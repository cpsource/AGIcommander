# AGIcommander Default Configuration
# This file defines the core configuration for the AGIcommander system

# System-wide settings
system:
  name: "AGIcommander"
  version: "0.1.0"
  log_level: "INFO"
  cycle_interval: 300  # seconds between autonomous cycles
  max_concurrent_tasks: 3
  safety_mode: true

# LLM Provider configurations
llm_providers:
  gemini:
    enabled: true
    default_model: "gemini-2.0-flash-exp"
    api_key: null  # Will use GOOGLE_API_KEY env var
    temperature: 0.1
    max_retries: 3
    timeout: 60
    models:
      - "gemini-2.0-flash-exp"
      - "gemini-1.5-pro"
      - "gemini-1.5-flash"
  
  openai:
    enabled: false
    default_model: "gpt-4"
    api_key: null  # Will use OPENAI_API_KEY env var
    temperature: 0.1
    max_retries: 3
    timeout: 60
    models:
      - "gpt-4"
      - "gpt-4-turbo"
      - "gpt-3.5-turbo"
  
  anthropic:
    enabled: false
    default_model: "claude-3-sonnet-20240229"
    api_key: null  # Will use ANTHROPIC_API_KEY env var
    temperature: 0.1
    max_retries: 3
    timeout: 60
    models:
      - "claude-3-opus-20240229"
      - "claude-3-sonnet-20240229"
      - "claude-3-haiku-20240307"
  
  xai:
    enabled: false
    default_model: "grok-beta"
    api_key: null  # Will use XAI_API_KEY env var
    temperature: 0.1
    max_retries: 3
    timeout: 60
    models:
      - "grok-beta"

# MCP Server configurations
mcp_servers:
  commander:
    enabled: true
    type: "code/commander"
    config:
      api_key: null  # Will inherit from llm_providers.gemini.api_key
      auto_confirm: false
      backup_files: true
      max_file_size: 1048576  # 1MB
      excluded_dirs: ["__pycache__", ".git", "node_modules", ".env"]
  
  introspection:
    enabled: true
    type: "self_reflection/introspect"
    config:
      assessment_interval: 3600  # seconds
      capability_tracking: true
      performance_metrics: true
  
  memory:
    enabled: true
    type: "memory/vector_db"
    config:
      database_type: "chroma"
      persist_directory: "memory/vector"
      collection_name: "agicommander_memory"
      embedding_model: "sentence-transformers/all-MiniLM-L6-v2"
  
  research:
    enabled: false
    type: "learning/research"
    config:
      search_engine: "tavily"
      api_key: null  # Will use TAVILY_API_KEY env var
      max_results: 10
      synthesis_model: "gemini"
  
  github:
    enabled: false
    type: "external/github"
    config:
      token: null  # Will use GITHUB_TOKEN env var
      default_owner: null
      default_repo: null

# Agent configurations
agents:
  developer:
    enabled: true
    type: "developer"
    config:
      primary_llm: "gemini"
      fallback_llm: "gemini"  # Same for now
      tools:
        - "commander"
        - "introspection"
        - "memory"
      max_iterations: 5
      code_quality_checks: true
      test_execution: false
  
  learner:
    enabled: false
    type: "learner"
    config:
      primary_llm: "gemini"
      tools:
        - "research"
        - "memory"
        - "introspection"
      learning_goals:
        - "code_quality_improvement"
        - "new_technologies"
        - "architecture_patterns"
      max_research_depth: 3

# Safety and security settings
safety:
  human_approval_required:
    - "self_modification"
    - "external_api_calls"
    - "file_deletion"
    - "system_configuration"
  
  sandbox_mode: true
  backup_before_changes: true
  max_file_modifications: 50
  allowed_file_extensions:
    - "py"
    - "js"
    - "ts"
    - "html"
    - "css"
    - "json"
    - "yaml"
    - "yml"
    - "md"
    - "txt"
  
  forbidden_paths:
    - "/etc"
    - "/usr"
    - "/bin"
    - "/sbin"
    - "/.git"
  
  rate_limits:
    api_calls_per_minute: 60
    file_operations_per_minute: 100
    llm_requests_per_hour: 1000

# Memory and persistence settings
memory:
  vector_database:
    type: "chroma"
    persist_directory: "memory/vector"
    collection_prefix: "agi_"
  
  relational_database:
    type: "sqlite"
    database_path: "memory/relational/agicommander.db"
  
  cache:
    type: "redis"
    host: "localhost"
    port: 6379
    db: 0
    ttl: 3600  # seconds
  
  retention:
    logs_days: 30
    cache_days: 7
    vector_embeddings_days: 90

# Monitoring and observability
monitoring:
  enabled: true
  metrics_collection: true
  performance_tracking: true
  error_reporting: true
  
  dashboards:
    enabled: false
    port: 8080
    
  alerts:
    enabled: true
    email_notifications: false
    webhook_url: null

# Development and debugging
development:
  debug_mode: false
  verbose_logging: false
  profile_performance: false
  save_intermediate_results: true
  
  testing:
    run_safety_tests: true
    validate_outputs: true
    mock_external_apis: false

# File processing defaults
file_processing:
  default_extensions: ["py"]
  recursive_search: false
  exclude_patterns:
    - "*.pyc"
    - "__pycache__/*"
    - ".git/*"
    - "node_modules/*"
    - "*.log"
  
  backup:
    enabled: true
    suffix: ".backup"
    max_backups: 5
  
  validation:
    syntax_check: true
    format_check: false
    lint_check: false

# Integration settings
integrations:
  github:
    auto_commit: false
    commit_message_template: "[AGIcommander] {summary}"
    branch_prefix: "agi/"
  
  docker:
    enabled: false
    default_image: "python:3.11-slim"
    resource_limits:
      memory: "512m"
      cpu: "0.5"
  
  huggingface:
    cache_dir: "memory/hf_cache"
    models:
      embedding: "sentence-transformers/all-MiniLM-L6-v2"
      summarization: "facebook/bart-large-cnn"

# Autonomous operation settings
autonomous:
  enabled: false  # Start with manual mode
  max_iterations: 10
  goal_oriented: true
  
  learning:
    continuous: true
    save_insights: true
    share_knowledge: false
  
  self_improvement:
    enabled: false  # Very experimental
    require_approval: true
    backup_system: true
    rollback_capability: true

# API and external service settings
external_apis:
  tavily:
    enabled: false
    api_key: null
    max_requests_per_day: 1000
  
  serper:
    enabled: false
    api_key: null
    max_requests_per_day: 2500
  
  wolfram:
    enabled: false
    app_id: null
    max_requests_per_day: 2000

