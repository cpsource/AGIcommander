"This subdirectory explores an approach to reduce neural network training time by separating metadata from text and using a two-stage training process:

Stage 1: Train the network on metadata first, then freeze those layers
Stage 2: Train on the actual text data with the metadata layers frozen

The approach involves:

Running sentence text through semantic and metadata pre-processors
Splitting training into two distinct phases
Leveraging metadata to bootstrap the learning process

I have various tools available through the MCP interface. Could you create a README-pre-processor.md file that outlines this approach and provide sample code to implement this two-stage training strategy?"
